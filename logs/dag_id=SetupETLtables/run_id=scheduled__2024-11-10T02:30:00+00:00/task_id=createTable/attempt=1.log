[2024-11-11T20:05:58.597+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-11T20:05:58.724+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SetupETLtables.createTable scheduled__2024-11-10T02:30:00+00:00 [queued]>
[2024-11-11T20:05:58.766+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SetupETLtables.createTable scheduled__2024-11-10T02:30:00+00:00 [queued]>
[2024-11-11T20:05:58.770+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-11-11T20:05:58.848+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): createTable> on 2024-11-10 02:30:00+00:00
[2024-11-11T20:05:58.907+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'SetupETLtables', 'createTable', 'scheduled__2024-11-10T02:30:00+00:00', '--job-id', '180', '--raw', '--subdir', 'DAGS_FOLDER/etl_table_snowflake.py', '--cfg-path', '/tmp/tmpvz6e6i44']
[2024-11-11T20:05:58.921+0000] {standard_task_runner.py:91} INFO - Job 180: Subtask createTable
[2024-11-11T20:05:58.922+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=201) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-11-11T20:05:58.922+0000] {standard_task_runner.py:63} INFO - Started process 237 to run task
[2024-11-11T20:05:59.053+0000] {task_command.py:426} INFO - Running <TaskInstance: SetupETLtables.createTable scheduled__2024-11-10T02:30:00+00:00 [running]> on host 599a8e9540bd
[2024-11-11T20:05:59.188+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SetupETLtables' AIRFLOW_CTX_TASK_ID='createTable' AIRFLOW_CTX_EXECUTION_DATE='2024-11-10T02:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-11-10T02:30:00+00:00'
[2024-11-11T20:05:59.191+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-11T20:05:59.204+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-11-11T20:05:59.206+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-6.10.4-linuxkit-aarch64-with-glibc2.36
[2024-11-11T20:05:59.208+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-11T20:06:00.002+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-11T20:06:00.025+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_table_snowflake.py", line 61, in createTable
    cur = return_snowflake_conn()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_table_snowflake.py", line 30, in return_snowflake_conn
    conn = hook.get_conn()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 287, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 55, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 442, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 745, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1073, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1373, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 401, in authenticate
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.DatabaseError: 250001 (08001): None: Failed to connect to DB: rab26384.snowflakecomputing.com:443. Your free trial has ended and all of your virtual warehouses have been suspended. Add billing information in the Snowflake web UI to continue using the full set of Snowflake features.
[2024-11-11T20:06:00.060+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=SetupETLtables, task_id=createTable, run_id=scheduled__2024-11-10T02:30:00+00:00, execution_date=20241110T023000, start_date=20241111T200558, end_date=20241111T200600
[2024-11-11T20:06:00.102+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 180 for task createTable (250001 (08001): None: Failed to connect to DB: rab26384.snowflakecomputing.com:443. Your free trial has ended and all of your virtual warehouses have been suspended. Add billing information in the Snowflake web UI to continue using the full set of Snowflake features.; 237)
[2024-11-11T20:06:00.132+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-11-11T20:06:00.169+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-11T20:06:00.173+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
